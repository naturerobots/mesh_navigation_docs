{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":"Mesh Navigation Documentation"},{"location":"#documentation","title":"Documentation","text":"<p>This documentation is under construction. It will contain both explanations for more applied users and for developers.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<p>This documentation cosists of several examples, guides and conceptual explanations to give users a more thorough understanding of mesh_navigation.</p> <p>Getting Started</p> <ul> <li>Overview</li> <li>Installation</li> </ul> <p>Documentation</p> <ul> <li>Theory</li> <li>Tutorials</li> <li>Library</li> <li>Guides</li> </ul>"},{"location":"#contributions","title":"Contributions","text":"<p>You are welcome to contribute to the docs of mesh_navigation! Thorough and clear documentation is essential. You can help us by correcting mistakes, improving content, or adding examples that facilitate user navigation and usage of the project. Please submit any documentation-related issues to the repository mesh_navigation_docs. If you're making fixes or adding examples, don\u2019t hesitate to submit a pull request afterward!</p>"},{"location":"#pr-workflow","title":"PR workflow","text":"<p>How to contribute to this documentation via pull requests:</p> <ol> <li>Fork the repository: mesh_navigation_docs.</li> <li>Make changes on your forked repository.</li> <li>Check locally on your machine if mkdocs is able to compile your changes (instructions).</li> <li>Go to Github and click \"Pull Request\", select this repository's \"main\" branch as target.</li> <li>If you added new content, please provide a brief explanation of why you believe it is beneficial for the documentation.</li> <li>Send PR</li> </ol>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#from-source","title":"From Source","text":"<p>Important</p> <p>Building from source is currently the only available option. Feel free to reach out to us, if you want to support us in uploading pre-built binaries somewhere.</p> <p>You need a working ROS 2 installation. We target humble at the moment. Go into a ROS 2 workspace's source directory cd $YOUR_ROS_WS/src and clone the tutorial code </p> <pre><code>git clone git@github.com:naturerobots/mesh_navigation.git\n</code></pre>"},{"location":"installation/#get-the-mesh-navs-ros-2-dependencies","title":"Get the mesh nav's ROS 2 dependencies:","text":"<p>Clone source dependencies using vcs-tool:</p> <pre><code>vcs import --input mesh_navigation/source_dependencies.yaml\n</code></pre> <p>Get packaged dependencies from within your ROS 2 workspace source directory:</p> <pre><code>rosdep install --from-paths . --ignore-src -r -y\n</code></pre>"},{"location":"installation/#build","title":"Build","text":"<p>Go to workspace root <code>cd $YOUR_ROS_WS</code> and run</p> <pre><code>colcon build --packages-up-to mesh_navigation\n</code></pre>"},{"location":"installation/#validate-build","title":"Validate Build","text":"<p>You can validate you installation by executing the very first of the mesh_navigation_tutorials.</p>"},{"location":"showcases/","title":"Showcases","text":""},{"location":"showcases/#driving-in-complex-environments","title":"Driving in Complex Environments","text":""},{"location":"showcases/#dynamic-obstacle-avoidance-kinematic-aware-control","title":"Dynamic Obstacle Avoidance &amp; Kinematic-aware control","text":""},{"location":"guides/","title":"Guides","text":"<p>We provide a collection of guides for both developers and applied users. Readers should have a basic understanding of what MeshNav is; if you are a complete beginner, we recommend starting with the tutorials instead. This section aims to include:</p> <ul> <li>Applying MeshNav on your own robots: tell us about your platform, show your environment, and present your goals using MeshNav as the solution.</li> <li>Structured overviews of working meshing pipelines with real robots.</li> <li>Explanations and examples showing how to use MeshNav interfaces in your own code.</li> <li>Any documentation that does not fit into either the \u201clibrary\u201d or the \u201ctutorials\u201d categories.</li> </ul> <p>Guides may be written in a blog-like style. Do not forget to document what you did to make MeshNav work and open a PR with your new guide. This can help newcomers get things running much faster.</p>"},{"location":"guides/mesh_mapping_glim/","title":"Building a Mesh Map With GLIM","text":"<p>This guide will teach you how to use the GLIM SLAM software to build mesh maps for use with MeshNav (the mesh can of course also be used for other applications).</p>"},{"location":"guides/mesh_mapping_glim/#recording-data","title":"Recording Data","text":"<p>The first step is to record data in your environment. Since GLIM is a range-based mapping framework your robot needs to feature some sort of range sensor, for example a 3D LiDAR or an RGB-D camera. You can reference GLIM's Sensor-setup-guide for more information on recommended sensors. GLIM expects to receive your data either via ROS2 topics or to read directly from a ROS2 bag file.</p> <p>I recommend to first record data to a bag file for better reproducibility and then run GLIM afterwards. Use the following command to start the recording and make sure to replace the <code>&lt;&gt;</code> parameters with the paths to your topics. <pre><code>ros2 bag record -s mcap --topics &lt;/pointcloud2/topic&gt; &lt;/imu/topic&gt;\n</code></pre> When your are done recording your environment you can stop the recording by pressing <code>CTRL-C</code>.</p> <p>Great! \ud83c\udf89</p> <p>Now copy the recorded bag file to the device you want to continue on.</p>"},{"location":"guides/mesh_mapping_glim/#environment-setup","title":"Environment Setup","text":"<p>The next step is to setup your environment with the tools necessary to continue. First install GLIM by following their installation instructions. The easiest and fastest way is to install using the PPA method. Then install GLIM for ROS (I recommend the CUDA version if you have a compatible system).</p> <p>Next create a new colcon workspace to build the necessary glim_scan_saver extension and the slam_to_mesh mesh generation tool: <pre><code>mkdir -p mesh_ws/src\ncd mesh_ws/src\n</code></pre> and clone the source repositories: <pre><code># slam_to_mesh tool\ngit clone https://github.com/JustusBraun/slam_to_mesh.git\n\n# Plugin to export undeskewed point clouds from GLIM\ngit clone https://github.com/JustusBraun/glim_scan_saver_ext.git\n</code></pre> The <code>slam_to_mesh</code> tool uses the LVR2 C++ library in the background. If you are using Ubuntu 24 you can download a prebuild <code>.deb</code> archive from the releases page and install using apt: <pre><code>apt install ./path/to/archive\n</code></pre> If you are not using Ubuntu 24 (or want to build from source) you can always build from source by cloning the LVR2 repository into the workspace: <pre><code>git clone https://github.com/uos/lvr2.git\n</code></pre> Make sure to follow the instructions in the LVR2 README to ensure the necessary dependencies are installed.</p> <p>Now you can build your workspace: <pre><code>cd ..\ncolcon build --cmake-args \" -DCMAKE_BUILD_TYPE=Release\"\n</code></pre></p>"},{"location":"guides/mesh_mapping_glim/#running-glim-slam","title":"Running GLIM SLAM","text":""},{"location":"guides/mesh_mapping_glim/#configure-glim","title":"Configure GLIM","text":"<p>Before you can run GLIM with your dataset you need to adjust the configuration to reflect your setup. First go to the root of your workspace and create a copy of GLIM's <code>config</code> directory: <pre><code>cp -r /opt/ros/$ROS_DISTRO/share/glim/config/ .\n</code></pre> If you build GLIM from source you can find the config folder in the root of GLIM's source tree.</p> <p>Then follow the steps outlined in the Getting Started section of GLIM's documentation to adjust your configuration files. The <code>imu_topic</code> and <code>points_topic</code> in the <code>config_ros.json</code> file tell GLIM which topics to read the IMU and LiDAR data from. Set them to the topics you recorded in the first section. You also need to add the <code>glim_scan_saver_ext.so</code> extension model to the <code>extension_modules</code> list to ensure that GLIM exports the individual pointclouds for us to use later.</p> Enabling the glim_scan_saver extension module <pre><code>\"glim_ros\": {\n    ...\n    \"keep_raw_points\": true // SET THIS TO TRUE IF YOU WANT FULL RESOLUTION LIDAR SCANS\n    ...\n    // Extension modules\n    \"extension_modules\": [\n      \"libmemory_monitor.so\",\n      \"libstandard_viewer.so\",\n      \"librviz_viewer.so\",\n      \"libglim_scan_saver_ext.so\" // THIS IS THE IMPORTANT LINE\n    ],\n    ...\n}\n</code></pre> <p>To fuse the IMU and pointcloud data GLIM needs to know the transformation between the IMU and range sensor coordinate systems. The transform must be written to the <code>T_lidar_imu</code> parameter in the <code>config_sensors.json</code> file. You should read GLIM's documentation page on parameters to tune the configuration to get the best mapping results with your sensor setup.</p>"},{"location":"guides/mesh_mapping_glim/#run-the-slam","title":"Run the SLAM","text":"<p>Now that configuration is complete you can run GLIM on your dataset. I will use the downsampled example bag file provided on GLIM's Getting Started page. Run GLIM with your custom configuration, make sure to replace the <code>&lt;&gt;</code> parameter with the path to your bag file. <pre><code>ros2 run glim_ros glim_rosbag &lt;path/to/your/bagfile&gt; --ros-args -p config_path:=$(realpath config/)\n</code></pre> This will open a window where you can watch the mapping process: </p> <p>After GLIM is done processing your bag file you can close the window and the resulting map will be saved to <code>/tmp/dump</code>. You can now optionally use the <code>offline_viewer</code> provided in the <code>glim_ros</code> package to manually add loop-closures and optimize the map. When you are done editing your map, use the <code>File</code> menu to save your map to a folder of your choice. If you do this you need to manually copy the <code>deskewed_scans/</code> directory from <code>/tmp/dump/</code> to the new map directory.</p>"},{"location":"guides/mesh_mapping_glim/#generating-the-mesh-map","title":"Generating the Mesh Map","text":"<p>Now we can use our exported scans and the trajectory generated by GLIM to create a triangle mesh map. For this now use the <code>slam_to_mesh</code> tool with the following command and replace the paths to the <code>traj_lidar.txt</code> file and <code>deskewed_scans</code> directory with the paths to your results:</p> <pre><code>slam_to_mesh --poses /tmp/dump/traj_lidar.txt --poses-filetype-hint tum --scans /tmp/dump/deskewed_scans/ --displacement 0.3 1.0\n</code></pre> <p>The <code>--displacement 0.3 1.0</code> flag reduces the number of scans processed by only adding a scan when the robot moved <code>0.3</code> meters or changed orientation by <code>1.0</code> radian. This reduces the necessary computation workload and can lead to reduced artifacts in the mesh from moving objects in the point clouds.</p> <p>The mesh generated from the example dataset looks as follows: </p> <p>The mesh can then be further processed with tools like MeshLab to remove artifacts and reduce the number of faces. For more information on mesh post-processing take a look at the Tutorials page.</p>"},{"location":"guides/meshnav_plugins/","title":"Creating MeshNav Plugins","text":"<p>MeshNav provides plugin interfaces that allow new cost layers to be developed by others who want to keep their code separate from the core MeshNav source. This document offers some starting points for exploring how a plugin can be implemented.</p> <p>Note</p> <p>This guide currently only points to specific entry points in related code bases. However, it would greatly benefit from real examples. Feel free to open a PR with your improvements!</p>"},{"location":"guides/meshnav_plugins/#cost-layer","title":"Cost Layer","text":"<p>MeshNav already provides a set of layers that you can use out of the box. If they are not sufficient for your specific task, you can create your own layer using MeshNav\u2019s <code>AbstractLayer</code> plugin interface.</p> <p>MeshNav itself implements all of its existing cost layers using this interface, bundled in the <code>mesh_layers</code> package. Since it is a separate package, <code>mesh_layers</code> can be placed anywhere inside your ROS workspace\u2019s <code>src</code> directory. As a demonstration, you can optionally move this package one level up:</p> <pre><code>mv your_ros_ws/src/mesh_navigation/mesh_layers your_ros_ws/src/mesh_layers\n</code></pre> <p>After doing this, you can still compile the ROS workspace as before. This shows that you can also write your own layer (or a set of layers) for MeshNav in your own package, following the example provided by the <code>mesh_layers</code> package.</p> <p>This allows you to keep the code within your own codebase while still contributing to the MeshNav project.</p> <p>Example Code: https://github.com/naturerobots/mesh_navigation/tree/main/mesh_layers</p>"},{"location":"guides/meshnav_plugins/#planner","title":"Planner","text":"<p>MeshNav\u2019s planners are implemented through the MeshPlanner plugin interface. If the existing planners do not cover your use case, you can implement your own planner plugin.</p> <p>The default planners are located in packages named <code>dijkstra_mesh_planner</code> and <code>cvp_mesh_planner</code>. Similar as for the <code>mesh_layers</code> package in the Cost Layer section, those packages are itself only plugins of the MeshNav's plugin interface and can be seen as example to write an own customized planner plugin.</p> <p>Example Code: https://github.com/naturerobots/mesh_navigation/tree/main/dijkstra_mesh_planner</p>"},{"location":"guides/meshnav_plugins/#controller","title":"Controller","text":"<p>MeshNav\u2019s controllers use the <code>MeshController</code> plugin interface from <code>mbf_mesh_core</code>. If you want to implement a different control strategy or support custom kinematic models, you can create your own controller plugin.</p> <p>The most complete example available is the MeshMPPI controller. It is provided in a separate repository, which clearly demonstrates how controller plugins can live outside the main <code>mesh_navigation</code> codebase while still integrating cleanly with MeshNav.</p> <p>Studying MeshMPPI is the recommended starting point, since it shows how a controller plugin can be packaged independently from the core navigation stack.</p> <p>Example Code:   MeshMPPI - https://github.com/uos/mesh_mppi</p>"},{"location":"library/","title":"Library","text":"<p>This section gives a more in-depth description of MeshNav seen as a library / as a plugin system which might be of interest for 3D navigation developers. MeshNav provides plugin interfaces for</p> <ul> <li>Path Planning</li> <li>Motion Control</li> <li>Mesh Layers</li> </ul> <p>which means, developer can use what's already there and implement own layers/planners/controllers on top, while beeing able to keep their code in their own codebases.</p>"},{"location":"library/#package-structure","title":"Package Structure","text":"<p>This mesh_navigation stack provides a navigation server for Move Base Flex (MBF). It provides a couple of configuration files and launch files to start the navigation server with the configured layer plugins for the layered mesh map, and the configured planners and controller to perform path planning and motion control in 3D (or more specifically on 2D-manifold). </p> <p>The package structure is as follows:</p> <ul> <li> <p><code>mesh_navigation</code> The corresponding ROS meta package.</p> </li> <li> <p><code>mbf_mesh_core</code> contains the plugin interfaces derived from the abstract MBF plugin interfaces to initialize planner and controller plugins with one <code>mesh_map</code> instance. It provides the following three interfaces: </p> <ul> <li>MeshPlanner - <code>mbf_mesh_core/mesh_planner.h</code></li> <li>MeshController - <code>mbf_mesh_core/mesh_controller.h</code></li> <li>MeshRecovery - <code>mbf_mesh_core/mesh_recovery.h</code></li> </ul> </li> <li> <p><code>mbf_mesh_nav</code> contains the mesh navigation server which is built on top of the abstract MBF navigation server. It uses the plugin interfaces in <code>mbf_mesh_core</code> to load and initialize plugins of the types described above.</p> </li> <li> <p><code>mesh_map</code> contains an implementation of a mesh map representation building on top of the generic mesh interface implemented in lvr2. This package provides a layered mesh map implementation. Layers can be loaded as plugins to allow a highly configurable 3D navigation stack for robots traversing on the ground in outdoor and rough terrain.</p> </li> <li> <p><code>mesh_layers</code> The package provides a couple of mesh layers to compute trafficability/traversibility properties of the terrain. Furthermore, these plugins have access to the HDF5 map file and can load and store layer information. The mesh layers can be configured for the robots abilities and needs. Currently we provide the following layer plugins: </p> <ul> <li>HeightDiffLayer - <code>mesh_layers/HeightDiffLayer</code></li> <li>RoughnessLayer - <code>mesh_layers/RoughnessLayer</code></li> <li>SteepnessLayer - <code>mesh_layers/SteepnessLayer</code></li> <li>RidgeLayer - <code>mesh_layer/RidgeLayer</code></li> <li>ClearanceLayer - <code>mesh_layers/ClearanceLayer</code></li> <li>InflationLayer - <code>mesh_layers/InflationLayer</code></li> <li>BorderLayer - <code>mesh_layers/BorderLayer</code></li> <li>ObstacleLayer - <code>mesh_layers/ObstacleLayer</code></li> </ul> </li> <li> <p><code>dijkstra_mesh_planner</code> contains a mesh planner plugin providing a path planning method based on Dijkstra's algorithm. It plans by using the edges of the mesh map. The propagation start a the goal pose, thus a path from every accessed vertex to the goal pose can be computed. This leads to a sub-optimal potential field, which highly depends on the mesh structure.</p> </li> <li> <p><code>cvp_mesh_planner</code> contains a Fast Marching Method (FMM) wave front path planner to take the 2D-manifold into account. This planner is able to plan over the surface, due to that it results in shorter paths than the <code>dijkstra_mesh_planner</code>, since it is not restricted to the edges or topology of the mesh. A comparison is shown below. Please refer to the paper <code>Continuous Shortest Path Vector Field Navigation on 3D Triangular Meshes for Mobile Robots</code>.</p> </li> </ul>"},{"location":"library/controller_plugin/","title":"Controller Plugin","text":"<p>Important</p> <p>Under construction. Go to the guide MeshNav Plugins for now.</p>"},{"location":"library/cost_layer_plugin/","title":"Cost Layer Plugin","text":"<p>Important</p> <p>Under construction. Go to the guide MeshNav Plugins for now.</p>"},{"location":"library/planner_plugin/","title":"Planner Plugin","text":"<p>Important</p> <p>Under construction. Go to the guide MeshNav Plugins for now.</p>"},{"location":"theory/","title":"Overview","text":"<p>Meshes provide a powerful representation for path planning on uneven terrain. Unlike grid-based maps, which discretize the environment into fixed cells, meshes describe the terrain as a continuous surface composed of connected planar elements. This allows them to capture fine-grained geometric details such as slopes, curvatures, and discontinuities that are critical for determining vehicle traversibility. By explicitly encoding surface normals and connectivity, meshes make it possible to evaluate vehicle stability, slope constraints, and ground clearance in a natural and efficient way.</p> <p>Another advantage of mesh-based representations is their adaptability: the resolution can be refined in areas of interest while remaining coarser elsewhere, balancing accuracy and efficiency. Meshes also allow semantic or traversibility information to be directly attached to vertices, edges, or faces, enabling flexible cost modeling during planning. Since a mesh inherently induces a graph structure, it integrates seamlessly with common planning algorithms such as Dijkstra, A, D, or sampling-based methods.</p> <p>In short, meshes combine geometric fidelity with computational efficiency, avoiding the discretization artifacts of raster-based maps while providing a natural substrate for terrain-aware navigation. These properties make them especially well-suited for ground vehicle path planning in complex, uneven environments, and form the theoretical foundation of the MeshNav library.</p> Pluto Robot Botanical Garden Osnabr\u00fcck"},{"location":"theory/control/","title":"Control","text":"<p>In classic mobile robot navigation, we like to distinguish between global path planning and local motion planning to balance long-term goals with real-time feasibility. The local planner (or controller), adapts a route to the robot\u2019s immediate surroundings and dynamics, handling obstacles and uncertainties as they appear. Modern navigation on 3D surface meshes requires control strategies that can follow complex terrain while respecting the robot's kinematics. MeshNav provides multiple controllers tailored to this task\u2014from a simple vector-field\u2013based controller to a full Model Predictive Path Integral (MPPI) controller. This section introduces the available controllers, explains how they operate, and highlights when each should be used.</p>"},{"location":"theory/control/#vector-field-controller","title":"Vector Field Controller","text":"<p>The vector field controller is the default controller used in the tutorials. It takes the vector field that was attached to the mesh by the planner and controls the robot along the field until it arrives at the desired goal.</p> <p>Source Code: mesh_controller.</p> No Obstacle Avoidance <p>In the current implementation (!), the vector field does not react to the new dynamic obstacle layer. Therefore, it is not possible to respond to dynamic obstacles. Implementing this capability would be a substantial improvement. Don't forget to open a PR!</p>"},{"location":"theory/control/#mesh-mppi","title":"Mesh MPPI","text":"<p>MeshMPPI is an adaptation of the model predictive path integral (MPPI) control algorithm to surface meshes. The MPPI algorithm generates control signals by simulating the trajectories resulting from a set of random samples. This adaptation constrains the trajectory prediction to the surface defined by a triangular mesh. The implementation provided in this repository integrates the MeshMPPI algorithm into the ROS 2\u2013based MeshNav 3D navigation stack.</p> <p>It can be used when extra attention is needed to ensure that motion planning is both kinematically and terrain feasible. It currently implements two kinematic models that can be used with either differential-drive or bicycle-drive robots. Furthermore, it reacts to dynamic cost layers, enabling it to avoid dynamic or previously unmapped obstacles. Additionally, it provides a mechanism to easily extend the controller with custom kinematic models.</p> <p>Source Code: mesh_mppi, developed at Osnabr\u00fcck University (UOS).</p>"},{"location":"theory/mesh_maps/","title":"Mesh Maps: Meshes as Environmental Representation for Robotics Tasks","text":"<p>Navigation is the task of going from A to B. Or, in other words, changing the state of A as long as it reaches B. It historically includes:</p> <ul> <li>Knowing the state of A: Localization</li> <li>Planning a path to B: Path Planning / Global Planning</li> <li>Planning and executing commands along the path, i.e. changing A: Controlling / Local Planning</li> </ul> <p>Maps are used to achieve this. Your vacuum cleaner is probably using a 2D occupancy grid for localization and for planning paths to B. It is also possible to use those grids for 3D navigation, by applying steepness information to them. However, there will always be a situation which is not representable, since it is simply not possible to represent a 3D environment by a 2D map. I promise you that I will find a situation where any \"enriched\" 2D map will break.</p> <p>Therefore, we tried to find a 3D representation for a map that is computationally efficient for all the operations we need, has a low memory footprint, and is capable of representing even challenging environments. For this guide, we reduce the choice to three potential data structures: point clouds, voxel-based maps, triangle meshes.</p>"},{"location":"theory/mesh_maps/#memory-efficiency","title":"Memory-efficiency","text":"<p>In the following guide, we create simple but realistic examples to show how mapping is done using those three representations. We start by creating the following world which resembles a cross-section of a hill next to a valley.</p> <p></p> <p>We call this world \"Alps-world\". Now we make a little mind game for finding a memory-friendly data structure: Represent the surface by 7 primitives. A primitive of a  - point cloud is simply a point. - voxel-based map is a voxel or in 2D a square. - triangle mesh is a triangle or in 2D a line.</p>"},{"location":"theory/mesh_maps/#pcd","title":"PCD","text":"<p>Representing the Alps-world's surface by a point cloud using 7 primitives, i.e. points, could result in the following map:</p> <p></p> <p>This representation is the most raw form of building a map from range sensor data, e.g. LiDAR, as every point can be an unchanged range measurement. It doesn't contain any interpolation error in between those points, since we are not interpolating inside the map itself.</p> <p>However, for navigation, the problem is that we don't know what is between those points. For example there can be another world represented by the same point cloud map:</p> Alps 1 Alps 2"},{"location":"theory/mesh_maps/#voxel-based","title":"Voxel-based","text":"<p>Representing the Alps world's surface by a voxel-based map using 7 primitives, i.e. squares, could result in the following map:</p> <p></p> <p>In contrast to the point cloud map, there are no gaps anymore; this representation describes the surface completely. It also means we cannot generate many other worlds anymore that would result in the same map. On the other hand, we have to be more careful in placing such voxels, since they are interpolating the space by design. When we place a 10cm voxel it means 10cm of place is completly occupied by some solid material. So we have to measure this 10cm good enough to be sure about this. Imagine there was a 7cm hole, which we want to avoid since we can get stuck with our small wheels. If we are not careful enough, this would be interpolated by a 10cm voxel.</p>"},{"location":"theory/mesh_maps/#meshes","title":"Meshes","text":"<p>Representing the Alps world's surface by a triangle mesh using 7 primitives, i.e. lines, could result in the following map:</p> <p></p> <p>(Red: Vertices, Black: Triangles)</p> <p>Before giving any explanations: Which of the presented representation would you chose?</p> <p>In contrast to PCDs, and same as voxel-based maps we can describe the surface completely. Similar to voxel-based approaches we also have to carefully place primitives. An advantage over voxel-based approaches is that we can describe the world more accurately with the same number of primitives. You can see this quality by how the map resembles the real world. Also, consider how many different worlds you can come up with that would result in this map. Not proven, but I guess it's less than for the voxel-based data structure.</p>"},{"location":"theory/mesh_maps/#accuracy","title":"Accuracy","text":"<p>The more primitives you \"invest\", the more accurate a PCD can describe the measured world.</p> <p>Voxel-based maps accuracy are bound to the minimum voxel size. Normally you choose the voxel resolution application-dependent. The best way of getting the feeling for that is playing Minecraft.</p> <p>With triangle meshes, we can make use of their inherent adaptive resolution: We can represent planar regions with only a few triangles, and a flat rectangular wall with only two triangles. But for objects or areas with greater detail, we can choose to invest more triangles in order to describe them more accurately.</p>"},{"location":"theory/mesh_maps/#traversal-properties","title":"Traversal Properties","text":"<p>You can traverse PCDs with some effort. Let's say we want to compute the curvature at a point based on its k-nearest neighbors. Without any prior computation we would first have to figure out all pairwise distances, second sort the points by distance. A smarter option is to construct an additional search structure, e.g. a kd-tree, to accelerate spatial searches. Even after those \"smart\" changes, the runtime will be not feasible on any robot's hardware. Or in simpler words: When you start to compute the curvature properties for each point of your PCD you will not be able to compute something else during that time. And do not forget: For the additional acceleration structure additional RAM is required. The third option would be to precompute a certain neighborhood for each point. Dependent on the neighborhood size, the required RAM increases exponentially. For the worst-case formula search for \"fully-connected graph\". In simpler words: If you want to use your RAM for something else, don't do that.</p> <p>Given a voxel-based map, you can traverse over the neighborhood just by increasing spatial indices, which have a constant runtime or in big-O notation: $O(1)$. And that is possible without any additional search structure on top of it.</p> <p>Given the same resolution/density, triangle meshes have the same optimal runtime properties as voxel-based maps for neighborhood traversal. However, since in triangle meshes one can skip larger distances over flat regions, you can traverse larger distance in less number of operations.</p>"},{"location":"theory/mesh_maps/#simplicity","title":"Simplicity","text":"<p>PCD maps are simpler to handle than voxel-based maps, which are simpler to handle than mesh maps. To handle mesh maps effectively, more knowledge is required. Or in other words, it is easier to handle meshes wrong.</p>"},{"location":"theory/mesh_maps/#further-remarks","title":"Further Remarks","text":"<p>Using triangle meshes we gain more potential advantages: - We can draw on decades of development in computer graphics; both software and hardware, e.g. RTX units for raycasting or hardware for rendering. - Textures! We can apply fine-granular information, such as colors, to low-resolution geometries.</p>"},{"location":"theory/mesh_maps/#how-to-generate-maps","title":"How to generate maps?","text":"<p>Building such maps can be done by many different procedures ranging from hand-modeling, e.g. using CAD programs, to more automatic approaches such as simultaneous localization and mapping (SLAM), photogrammetry, bundle adjustment, .... The next guides give a brief overview how we use software from those categories. However, all methods are very interesting and I strongly recommend to gain deeper knowledge of the actual implementations and the related math.</p>"},{"location":"theory/path_planning/","title":"Path Planning","text":"<p>In classic mobile robot navigation, we like to distinguish between global path planning and local motion planning to balance long-term goals with real-time feasibility. The global planner provides a high-level route through the environment, ensuring the robot moves efficiently toward its destination. Mesh navigation provides several global planners designed to compute feasible paths across 3D surfaces. All implemented planners share the core principle of computing shortest paths on a triangular mesh. Depending on configuration, they can also take into account obstacle avoidance.</p>"},{"location":"theory/path_planning/#dijkstra-planner","title":"Dijkstra Planner","text":"<p>The Dijkstra Planner implements the classic Dijkstra's algorithm. It operates on the graph representation of the triangle mesh, where mesh vertices represent graph nodes and mesh edges represent graph edges.</p> <p></p> <p>This planner is well-suited for applications where simplicity, robustness, and deterministic behavior are desired, but it is limited to edge-based paths rather than continuous trajectories over the surface.</p>"},{"location":"theory/path_planning/#continuous-vector-field-planner","title":"Continuous Vector Field Planner","text":"<p>The Continuous Vector Field Planner (CVP) extends beyond edge-based search by planning directly over the surface of the mesh instead of its connectivity graph. CVP uses a wavefront propagation technique to generate a globally consistent vector field that encodes the continuous shortest path direction from any point on the mesh to the goal. Therefore, can flow smoothly across triangle faces, producing shorter and more natural trajectories than the ones found by the Dijkstra planner. Similar to Dijkstra, CVP can integrate surface costs, allowing navigation that avoids obstacles or prefers favorable terrain. This makes CVP particularly useful for mobile robots operating on uneven or natural terrain, where edge-restricted paths would otherwise be suboptimal or unnatural. Furthermore, CVP is less sensitive to the density of the triangles in the mesh.</p> <p></p> <p>Note</p> <p>For the theoretical background and implementation details, see:</p> <pre><code>@inproceedings{puetz21cvp,\n    author = {P\u00fctz, Sebastian and Wiemann, Thomas and Kleine Piening, Malte and Hertzberg, Joachim},\n    title = {Continuous Shortest Path Vector Field Navigation on 3D Triangular Meshes for Mobile Robots},\n    booktitle = {2021 IEEE International Conference on Robotics and Automation (ICRA)},\n    year = 2021,\n    url = {https://github.com/uos/mesh_navigation},\n    note = {Software available at \\url{https://github.com/uos/mesh_navigation}}\n}\n</code></pre> <p>It is available on IEEE Xplore.</p> <p>Config:</p> <pre><code>mesh_planner:\n  type: 'cvp_mesh_planner/CVPMeshPlanner'\n  cost_limit: 0.99 # Vertices with costs higher than this value will be avoided. Has to be set *below* the inflation layer inscribed value to avoid obstacles in planning\n  publish_vector_field: true\n</code></pre>"},{"location":"theory/path_planning/#obstacle-aware-planning","title":"Obstacle-aware planning","text":"<p>After the cost layers have been computed, the resulting vertex costs are transformed into edge costs inside the mesh map. In this step, the parameter of the mesh map <code>edge_cost_factor</code> determines how much the vertex costs are added (!) to the edge distance. We add the costs to the edge distances to preserve the admissible property of future heuristic search implementations: When using pre-computed distances or the air-line to the target as heuristics, the actual costs collected along the way will be always at least higher. </p> <p>Setting the <code>edge_cost_factor</code> parameter to zero will let the planners ignore all static obstacles. An example configuration that takes (static) obstacles into account while planning could be:</p> <pre><code>mesh_map:\n  # An edge cost equals the total costs that are collected along a \n  # triangle's edge by linearly interpolating the combined vertex costs\n  # This factor defines the factor that is used for the final edge weight\n  # -&gt; edge_weight = edge_length + edge_cost_factor * edge_cost\n  # This edge_weight is then passed to the global planner to search for \n  # the best path\n  # Note: Set this to 0.0 if you need the shortest path\n  edge_cost_factor: 5.0\n\n  # [...] Other parameters of mesh_map\n</code></pre>"},{"location":"theory/path_planning/#comparison","title":"Comparison","text":"Vector Field Planner Dijkstra Mesh Planner ROS Global Planner on 2.5D DEM"},{"location":"tutorials/","title":"Tutorials","text":"<p>Info</p> <p>This documentation is under construction. It will contain explanations for both applied users and developers. </p> <p>Throughout the tutorials, code snippets are occasionally provided to demonstrate the described concepts. Before continuing, make sure you have installed the MeshNav tutorials. Follow the installation instructions provided in the repository\u2019s top-level README file.</p> <p>You can test your installation by running:</p> <pre><code>ros2 launch mesh_navigation_tutorials mesh_navigation_tutorials_launch.py world_name:=tray\n</code></pre> <p>This command launches a simple world in Gazebo and opens an RViz window showing the mesh map of the environment.</p> Gazebo RViz <p>In RViz, click \u201cMesh Goal\u201d and draw an arrow somewhere on the map. The robot should start driving to the selected point. If this works, the installation was successful and you can proceed with the tutorials.</p>"},{"location":"tutorials/#applied-users","title":"Applied Users","text":"<p>This section explains how to get started with MeshNav. It then introduces documentation on applying these concepts to real-world scenarios through map-based localization and deliberation. Finally, we present tools for handling mesh maps, primarily by cross-referencing existing approaches and workflows for mesh mapping and editing.</p>"},{"location":"tutorials/#getting-started-with-meshnav","title":"Getting Started with MeshNav","text":"<ol> <li>Mesh Navigation</li> <li>Mesh Cost Layers</li> <li>Planner &amp; Controller</li> <li>Virtual Worlds</li> </ol>"},{"location":"tutorials/#sim-to-real","title":"Sim-to-Real","text":"<ul> <li>Map-based Localization</li> <li>Deliberation</li> </ul>"},{"location":"tutorials/#mesh-generation-editing","title":"Mesh Generation &amp; Editing","text":"<ul> <li>Mesh Mapping</li> <li>Repair Meshes</li> <li>Flatten Floor</li> <li>Align Mesh to Ground</li> <li>Shrink Faces</li> </ul>"},{"location":"tutorials/deliberation/","title":"Deliberation","text":"<p>This guide provides tutorials explaining how to integrate mesh navigation into well-known deliberation approaches such as behavior trees and similar frameworks, as listed in awesome-ros-deliberation.</p> <p>Note</p> <p>This section would love to be expanded. Feel free to contribute!</p>"},{"location":"tutorials/deliberation/#mbf-deliberation-meshnav-deliberation","title":"MBF Deliberation == MeshNav Deliberation","text":"<p>MeshNav uses the standardized, map-agnostic interfaces of Move Base Flex (MBF). Therefore, the standard path-planning and control actions in MeshNav can be integrated just like any other MBF implementation or plugin. We have collected simple examples for different deliberation mechanisms here: https://github.com/amock/mbf_deliberation.</p>"},{"location":"tutorials/localization/","title":"Localization","text":"<p>While navigating a robot to a target on the map, the robot's location relative to that map has to be known constantly. This is called localization (on a prior map). There are again many approaches to that. Monte Carlo Localization (MCL) is well known and has proven to be exceptionally robust for 2D navigation. However, it is rather computationally demanding. In 3D, it requires carefully designed software or special hardware to run online on the robot. Therefore, implementations of 3D MCL are rarely seen right now.</p> <p>However, other computationally more lightweight approaches exist. For example, pose tracking in meshes using the MICP-L method of the RMCL project. It assumes that the robot pose is roughly known in advance.</p> <p></p> <p>Hint</p> <p>The next steps in this section require RMCL to be compiled within your ROS workspace.</p> <p>Some nodes of the RMCL project are directly integrated within the tutorials. You can activate it's MICP-L pose tracking method  by setting the launch argument <code>localization</code> to <code>rmcl_micpl</code>.</p> <pre><code>ros2 launch mesh_navigation_tutorials mesh_navigation_tutorials_launch.py world_name:=tray localization:=rmcl_micpl\n</code></pre> <p>Whats happening internally: The localization that was previously given by the Gazebo simulation is now replaced by MICP-L, a method that continuously registers the LiDAR scans to the mesh map. Enabling a \"real\" localization has several advantages:</p> <ul> <li>Easier integration into real-world systems: Gazebo-like ground truth is usually not available there unless you have a tracking system.</li> <li>Realistic problems that could effect navigation algorithms: Localization latency, localization inaccuracies, localization failures, additional computational loads.</li> </ul> <p>Info</p> <p>For more details about the MICP-L method we refer to the paper or the ROSCon Talk.</p>"},{"location":"tutorials/localization/#localization-in-other-maps","title":"Localization in other maps","text":""},{"location":"tutorials/localization/#point-cloud-maps","title":"Point Cloud Maps","text":"<p>You can use a point cloud (PCD) map that is accurately aligned to the mesh as alternative map representation to do localization. The PCD typically comes from: - Sampling the mesh, using tools like CloudCompare - Using the PCD from a PCD SLAM approach before it was converted to a mesh</p> <p>Here is a list of some software packages for localization on such prior PCD maps:</p> Name Code mcl_3dl https://github.com/at-wat/mcl_3dl lidar_localization_ros2 https://github.com/rsasaki0109/lidar_localization_ros2 <p>In addition, many of the recently developed PCD SLAM packages have a localization-only mode that can be used to compute the required localization.</p> <p>But beware: Using this approach for large-scale maps could cause your RAM to suffer.</p>"},{"location":"tutorials/localization/#voxel-maps","title":"Voxel Maps","text":"<p>If a voxel-based representation is still available you can use one of the following map-based localization approaches:</p> Name Code TSDF MCL https://github.com/uos/tsdf_localization"},{"location":"tutorials/localization/#localization-using-gps","title":"Localization using GPS","text":"<p>If your mesh map is geo-referenced, you can use a GPS localization. However, GPS often lacks of accuracy at altitude / z-axis which has to be compensated. Furthermore, if the map is slightly wrong, GPS would give wrong results relative to the used map; even though its signal is optimal (!). Then, localization approaches based on matching sensor data to the map would produce more reliable results. </p>"},{"location":"tutorials/mesh_cost_layers/","title":"Cost Layer Generation","text":"<p>Cost layers are used inside of mesh navigation to assign parts of the mesh several properties that can be considered for path planning and local planning. For example</p> <ul> <li>traversibility properties such as roughness, friction, etc.</li> <li>lethal zones: such as borders of cliffs</li> <li>prohibition areas where the robot should not drive because of certain safety regulations</li> <li>obstacle layers: recording low-latency obstacle updates which can be used to avoid obstacles either in the planners or in the controllers</li> </ul>"},{"location":"tutorials/mesh_cost_layers/#static-cost-layers","title":"Static Cost Layers","text":"<p>Mesh Navigation provides a collection of layers that pre-compute static traversibility costs on the mesh surface. Each layer takes different geometric/semantic properties into account:</p> Layer Plugin Type Specifier Description of Cost Computation Example Image HeightDiffLayer <code>mesh_layers/HeightDiffLayer</code> height difference in a radius around the vertex RoughnessLayer <code>mesh_layers/RoughnessLayer</code> local radius based normal fluctuation SteepnessLayer <code>mesh_layers/SteepnessLayer</code> arccos of the normal's z coordinate RidgeLayer <code>mesh_layer/RidgeLayer</code> local radius based distance along normal. This can be useful to drive along ridge or bed structures in agricultural scenarios (e.g. potatoes, carrots, or onions). Hereby, the upper part of the ridges would have higher costs while the valleys would have low costs. This can be useful to plan vehicle wheel trajectories and only allow driving inside the ridge valleys (and thus not damage crops). ClearanceLayer <code>mesh_layers/ClearanceLayer</code> comparison of robot height and clearance along each vertex normal InflationLayer <code>mesh_layers/InflationLayer</code> by distance to a lethal vertex BorderLayer <code>mesh_layers/BorderLayer</code> give vertices close to the border a certain cost"},{"location":"tutorials/mesh_cost_layers/#dynamic-layers","title":"Dynamic Layers","text":""},{"location":"tutorials/mesh_cost_layers/#obstacle-layer","title":"Obstacle Layer","text":"<p>The obstacle layer enables the planner to recognize and navigate around obstacles. It subscribes to a topic providing obstacle points (e.g., from pre-segmented LiDAR data) and projects these points down onto the mesh surface. The vertices of the intersected faces are then marked as lethal, preventing the planner from finding paths through them.</p> <p>In most setups, an inflation layer is added directly after the obstacle layer. This layer expands the lethal regions to form a safety margin or buffer zone around detected obstacles. Within this zone, the robot can still plan paths, but it is encouraged to move cautiously and maintain a safe distance from potentially dynamic or unknown objects.</p> <p>To start with why obstacle avoidance is important, we start with showing what happens when you ignore it.</p> <pre><code>ros2 launch mesh_navigation_tutorials mesh_navigation_tutorials_launch.py world_name:=tray\n</code></pre> <p>Then:</p> <ol> <li>Place a ball in front of the robot using the Gazebo GUI elements top left.</li> <li>Go the RViz window and select a goal pose behind the ball (the dynamic obstacle).</li> </ol> <p>You will see the robot crashing into the ball.</p> <p>Unless you want to create a soccer robot, this is usually not a wanted behavior. Especially in reality, when it's not a ball but a human being. Fortunately, the obstacle layer can help us here. First, we need some kind of pre-filtered scan that only contains points of the dynamic points.</p> <p>Luckily, the integrated localization package RMCL already contains nodes to do that a very simplistic but fairly fast filtering of our scan points based on the mesh map. It removes points of a LiDAR scan that are close to the map. The remaining points are classified as \"unexpected\" and can pretty well be used as input for the obstacle layer.</p> <p>Warning</p> <p>The following command requires RMCL to be installed.</p> <p>Enable this pre-segmentation by calling</p> <pre><code>ros2 launch mesh_navigation_tutorials mesh_navigation_tutorials_launch.py world_name:=tray obtacle_segmentation:=rmcl_seg\n</code></pre> <p>After repeating the steps 1. and 2. from above, the ball is detected as dynamic obstacle, projected onto the obstacle, and finally considered during planning.</p> Parameter Type Description <code>robot_height</code> Float Height of the robot (in meters) considered for projection. You can use this to let small robots drive below tables. <code>max_obstacle_dist</code> Float Obstacles points farther away then this parameter's value are ignored. <code>topic</code> String Input obstacle points topic of message type <code>sensor_msgs/PointCloud2</code>"},{"location":"tutorials/mesh_cost_layers/#graph-layer-system","title":"Graph Layer System","text":"<p>The planner operates on a single cost layer that can have combined costs from other cost layers. Using the Graph Layer system, users can configure which cost layers contribute to it and with what weighting factors.</p> <p>On startup, all configured cost layers are loaded by the <code>MeshMap</code> and are stored in a dependency graph data structure. This dependency graph is a directed graph with an edge between two layers A and B if the layer A uses B as an input. An example of a layer that uses another layer as an input is the inflation layer, which inflates obstacles in the map to keep the robot at a safe distance.</p> <p>Computing the inflation layer can take up to several seconds in larger real-world meshes, which is a problem if we add moving obstacles to the map using the obstacle layer because we need to recompute the inflation layer every time the obstacle layer is updated. Our graph-based approach allows us to split the inflation layer computation into static obstacles, which are computed once when mesh navigation initializes, and dynamic obstacles, which are continuously updated but only affect a small region of the map around the robot and can therefore be inflated very fast.</p> <p>The following image shows an example layer configuration with static obstacles detected by three layers and dynamic obstacles. The AvgCombinationLayer and MaxCombinationLayer merge their respective input layers by merging the lethal vertices and calculating the cost for each vertex as the average and maximum of their respective input layers. The MaxCombinationLayer at the bottom is the final layer used by the planning and control plugins.</p> <p></p>"},{"location":"tutorials/mesh_navigation/","title":"Mesh Navigation (Quick-Start)","text":"<p>This tutorial aims to help quickly giving a feeling how to setup mesh_navigation properly and how to fine-tune several parameters. </p> <p>Important</p> <p>You need <code>mesh_navigation_tutorials</code> installed before continuing.</p> <p>Start the first example by calling:</p> <pre><code>ros2 launch mesh_navigation_tutorials mesh_navigation_tutorials_launch.py world_name:=floor_is_lava\n</code></pre> <p>You can change <code>floor_is_lava</code> by any world name that is available with this repository (see all by calling launch file with <code>--show-args</code>). Those are: </p> Name World Default Map Description tray This world is a rectangular area with a wall around the perimeter. floor_is_lava This world contains a square area with with two pits and a connecting section at a slightly higher elevation. parking_garage This world represents a parking garage with multiple floors connected by ramps. <p>Info</p> <p>See Virtual Worlds for more information about those and more realistic maps that are available within the tutorials.</p> <p>An RViz window opens showing a mesh map which is used by MeshNav for path planning and control. In order to make the robot move, find the \"Mesh Goal\" tool at the top. With it, you can click on any part of the mesh. Click and hold to set a goal pose.</p>"},{"location":"tutorials/mesh_navigation/#parameters","title":"Parameters","text":"<p>Note</p> <p>Note: Open this to access the most recent config file.</p> <p>A complete parameter file of mesh_navigation can look like this:</p>  Parameter File  <pre><code>move_base_flex:\n  ros__parameters:\n    global_frame: 'map'\n    robot_frame: 'base_footprint'\n    odom_topic: 'odom'\n\n    use_sim_time: true\n    force_stop_at_goal: true\n    force_stop_on_cancel: true\n\n    planners: ['mesh_planner']\n    mesh_planner:\n      type: 'cvp_mesh_planner/CVPMeshPlanner'\n      cost_limit: 0.99 # Vertices with costs higher than this value will be avoided. Has to be set *below* the inflation layer inscribed value to avoid obstacles in planning\n      publish_vector_field: true\n\n    planner_patience: 10.0\n    planner_max_retries: 2\n    project_path_onto_mesh: false\n\n    controllers: ['mesh_controller']\n    mesh_controller:\n      type: 'mesh_controller/MeshController'\n      ang_vel_factor: 7.0\n      lin_vel_factor: 1.0\n\n    controller_patience: 2.0\n    controller_max_retries: 4\n    dist_tolerance: 0.2\n    angle_tolerance: 0.8\n    cmd_vel_ignored_tolerance: 10.0\n\n    mesh_map:\n      # input\n      # In this examples, `mesh_file` is set dynamically from the launch file. \n      # you can also set it statically:\n      # mesh_file: '.../parking_garage.ply'\n      mesh_part: '/'\n      # storage\n      # mesh_working_file: 'parking_garage.h5'\n      mesh_working_part: 'mesh'\n\n      # half-edge-mesh implementation\n      # pmp (default), lvr\n      hem: pmp\n\n      # these are the layers the MeshMap will load into the layer graph\n      layers:\n        - border \n        - height_diff \n        - roughness \n        - static_combination \n        - static_inflation \n        - obstacle \n        - obstacle_inflation\n        - final\n\n      # this sets the layer used for planning and control\n      default_layer: 'final'\n\n      height_diff:\n        type: 'mesh_layers/HeightDiffLayer'\n        combination_weight: 1.0\n        threshold: 0.2\n\n      border:\n        type: 'mesh_layers/BorderLayer'\n        combination_weight: 1.0\n        border_cost: 1.0\n        threshold: 0.2\n\n      roughness:\n        type: 'mesh_layers/RoughnessLayer'\n        combination_weight: 1.0\n        threshold: 0.8\n\n      static_combination:\n        # This layer combines the three input layers by linearly combining vertex costs:\n        # -&gt; vertex_cost = layer1.combination_weight * layer1.vertex_cost + layer2.combination_weight * layer2.vertex_cost + ...\n        # The input layers' lethal vertices are accumulated in a combined set\n        type: 'mesh_layers/AvgCombinationLayer'\n        # The `inputs` parameter determines which layers are processed by this layer.\n        # If a layer does not process inputs, this parameter can be omitted\n        inputs: ['height_diff', 'border', 'roughness']\n\n      static_inflation:\n        type: 'mesh_layers/InflationLayer'\n        inputs: ['static_combination']\n        combination_weight: 1.0\n        inflation_radius: 1.5 # outer ring\n        inscribed_radius: 0.4 # inner ring\n        lethal_value: .inf\n        inscribed_value: 1.0\n        repulsive_field: false\n        cost_scaling_factor: 2.0\n\n      obstacle:\n        type: 'mesh_layers/ObstacleLayer'\n        combination_weight: 1.0\n        robot_height: 0.75\n        max_obstacle_dist: 10.0\n        topic: 'obstacle_points'\n\n      obstacle_inflation:\n        type: 'mesh_layers/InflationLayer'\n        inputs: ['obstacle']\n        combination_weight: 1.0\n        inflation_radius: 1.5 # outer ring\n        inscribed_radius: 0.4 # inner ring\n        lethal_value: .inf\n        inscribed_value: 1.0\n        repulsive_field: false\n        cost_scaling_factor: 2.0\n\n      final:\n        type: 'mesh_layers/MaxCombinationLayer'\n        inputs: ['static_inflation', 'obstacle_inflation']\n\n      # An edge cost equals the total costs that are collected along a \n      # triangle's edge by linearly interpolating the combined vertex costs\n      # This factor defines the factor that is used for the final edge weight\n      # -&gt; edge_weight = edge_length + edge_cost_factor * edge_cost\n      # This edge_weight is then passed to the global planner to search for \n      # the best path\n      # Note: Set this to 0.0 if you need the shortest path\n      edge_cost_factor: 5.0\n\n      # debug function: enable this, for publishing text markers with edge costs\n      publish_edge_weights_text: false\n\n      # debug/development function: enable this to log the update times of changing layers to a csv file\n      enable_layer_timer: false\n</code></pre> <p>The following sections give a brief explanation what those parameter are good for. </p>"},{"location":"tutorials/mesh_navigation/#general-parameters-mbf","title":"General Parameters (MBF)","text":"<p>The following parameters are related to Move Base Flex. If you miss some information here, we refer to MBFs documentation.</p> <pre><code>global_frame: 'map'\nrobot_frame: 'base_footprint'\nodom_topic: 'odom'\n\nforce_stop_at_goal: true\nforce_stop_on_cancel: true\n\ncontroller_patience: 2.0\ncontroller_max_retries: 4\ndist_tolerance: 0.2\nangle_tolerance: 0.8\ncmd_vel_ignored_tolerance: 10.0\n\nplanner_patience: 10.0\nplanner_max_retries: 2\n</code></pre> <p>The parameter <code>global_frame</code> sets the frame where the map is located in. The parameter <code>robot_frame</code> sets the frame of the robot base. A localization estimates the connection between the <code>global_frame</code> and the <code>robot_frame</code>, so make sure you have one running. You can check this by visualizing the tf-tree and searching for a path from the <code>global_frame</code> to the <code>robot_frame</code>. </p> <p><code>odom_topic</code> points to a topic where an odometry estimation of your robot is published to. The published messages have to be of type <code>nav_msgs/Odometry</code>. This <code>odom_topic</code> may provide motion information in higher frequency and is internally used to extrapolate from the last map localization. This becomes especially relevant if you have a low frequency localization in your map as it ensures short state estimation cycles for the controller.</p> <p>In reality, state estimation errors are propagated to the controller, as it relies on it. In the worst case, the localization relative to the map is completely lost, which causes the whole navigation to fail.  For the tutorials, however, the localization is perfect by default as it is provided by the Gazebo simulation. This helps to develop planning or controlling strategies since we don't inherit errors from the localization system. This means, if our newly developed planner or controller fails, we can be sure it's our fault. However, in order to check whether our newly developed planner or controller really works reliably, we must also take possible localization errors into account. Therefore, we are working on including localization strategies directly in the tutorials as well. Some of them are described here: Link.</p> <p>The other parameters are related to Move Base Flex. If you need more information about them, we refer to MBFs documentation.</p>"},{"location":"tutorials/mesh_navigation/#mesh-planners-and-controllers","title":"Mesh Planners and Controllers","text":"<p>The following parameters are describing what planners and controllers are loaded and how they are parameterized.</p> <pre><code># planner\nplanners: ['mesh_planner']\nmesh_planner:\n  type: 'cvp_mesh_planner/CVPMeshPlanner'\n  cost_limit: 0.8\n  publish_vector_field: true\n# controller\ncontrollers: ['mesh_controller']\nmesh_controller:\n  type: 'mesh_controller/MeshController'\n  ang_vel_factor: 7.0\n  lin_vel_factor: 1.0\n</code></pre> <p>In general, they are described in the exact same way you would do it for the 2d costmap navigation implementation of Move Base Flex - which is currently not existing for ROS 2, however you can orient at ROS 1 examples. The only difference for mesh navigation is that we are only allowed to load planners and controllers that can handle to move the robot over a triangle mesh's surface.</p> <p>The <code>planners</code> list contains the planners names, the <code>controllers</code> list contains the controllers names. All names in <code>planners</code> and <code>controllers</code> point to certain key-value pairs in the parameter file. In this example one mesh planner of type <code>cvp_mesh_planner/CVPMeshPlanner</code> is loaded and one controller of type <code>mesh_controller/MeshController</code> is used.</p> <p>One core feature that of MBF is to let the user switch different planners and controllers at runtime. For example, we might want to switch the robot's driving mode from a risky behavior to a more careful behavior for certain situations. This can be simply achieved by renaming the existing controller and giving them different parameters as follows:</p> <pre><code># planner\nplanners: ['mesh_planner']\nmesh_planner:\n  type: 'cvp_mesh_planner/CVPMeshPlanner'\n  cost_limit: 0.8\n  publish_vector_field: true\n# controller\ncontrollers: ['mesh_controller_careful', 'mesh_controller_risky']\nmesh_controller_careful:\n  type: 'mesh_controller/MeshController'\n  ang_vel_factor: 7.0\n  lin_vel_factor: 1.0\nmesh_controller_risky:\n  type: 'mesh_controller/MeshController'\n  ang_vel_factor: 20.0\n  lin_vel_factor: 10.0\n</code></pre> <p>You can then use e.g. a behavior tree to select a pre-parameterized controller, depending on the situation.</p>"},{"location":"tutorials/mesh_navigation/#mesh-map","title":"Mesh Map","text":"<p>The following parameters are used to describe general map information, the way the cost-layers are computed, and which cost-layers are considered for navigation.</p> <pre><code>mesh_map:\n  mesh_file: 'path/to/my_layered_mesh_map.ply'\n  mesh_part: '/' # reference to mesh\n\n  # list of available layers\n  layers:\n    - border\n    - height_diff\n    - roughness\n    - static_combination\n    - static_inflation\n    - obstacle\n    - obstacle_inflation\n    - final\n  [...]\n</code></pre>"},{"location":"tutorials/mesh_navigation/#dynamic-reconfigure","title":"Dynamic Reconfigure","text":"<p>Most of the parameters can be changed at run time to conveniently fine-tune certain cost-layer's parameters. Call</p> <pre><code>ros2 run rqt_reconfigure rqt_reconfigure\n</code></pre> <p>An rqt window will open in which you can change parameters of different parts of the mesh navigation.</p>"},{"location":"tutorials/planner_and_controller/","title":"Mesh Planner and Controller","text":"<p>In classic mobile robot navigation, we like to distinguish between global path planning and local motion planning to balance long-term goals with real-time feasibility. The global planner provides a high-level route through the environment, ensuring the robot moves efficiently toward its destination. The local planner, in turn, adapts this route to the robot\u2019s immediate surroundings and dynamics, handling obstacles and uncertainties as they appear. Importantly, this concept remains the same regardless of the underlying representation: whether navigation is performed on a 2D grid map or in a 3D mesh-based environment.</p>"},{"location":"tutorials/planner_and_controller/#global-planners","title":"Global Planners","text":"<p>Mesh navigation provides several global planners designed to compute feasible paths across 3D surfaces. All implemented planners share the core principle of computing shortest paths on a triangular mesh. Depending on configuration, they can also take into account obstacle avoidance.</p>"},{"location":"tutorials/planner_and_controller/#dijkstra-planner","title":"Dijkstra Planner","text":"<p>The Dijkstra Planner implements the classic Dijkstra's algorithm. It operates on the graph representation of the triangle mesh, where mesh vertices represent graph nodes and mesh edges represent graph edges.</p> <p></p> <p>This planner is well-suited for applications where simplicity, robustness, and deterministic behavior are desired, but it is limited to edge-based paths rather than continuous trajectories over the surface.</p>"},{"location":"tutorials/planner_and_controller/#continuous-vector-field-planner","title":"Continuous Vector Field Planner","text":"<p>The Continuous Vector Field Planner (CVP) extends beyond edge-based search by planning directly over the surface of the mesh instead of its connectivity graph. CVP uses a wavefront propagation technique to generate a globally consistent vector field that encodes the continuous shortest path direction from any point on the mesh to the goal. Therefore, can flow smoothly across triangle faces, producing shorter and more natural trajectories than the ones found by the Dijkstra planner. Similar to Dijkstra, CVP can integrate surface costs, allowing navigation that avoids obstacles or prefers favorable terrain. This makes CVP particularly useful for mobile robots operating on uneven or natural terrain, where edge-restricted paths would otherwise be suboptimal or unnatural. Furthermore, CVP is less sensitive to the density of the triangles in the mesh.</p> <p></p> <p>Note</p> <p>For the theoretical background and implementation details, see:</p> <pre><code>@inproceedings{puetz21cvp,\n    author = {P\u00fctz, Sebastian and Wiemann, Thomas and Kleine Piening, Malte and Hertzberg, Joachim},\n    title = {Continuous Shortest Path Vector Field Navigation on 3D Triangular Meshes for Mobile Robots},\n    booktitle = {2021 IEEE International Conference on Robotics and Automation (ICRA)},\n    year = 2021,\n    url = {https://github.com/uos/mesh_navigation},\n    note = {Software available at \\url{https://github.com/uos/mesh_navigation}}\n}\n</code></pre> <p>It is available on IEEE Xplore.</p> <p>Config:</p> <pre><code>mesh_planner:\n  type: 'cvp_mesh_planner/CVPMeshPlanner'\n  cost_limit: 0.99 # Vertices with costs higher than this value will be avoided. Has to be set *below* the inflation layer inscribed value to avoid obstacles in planning\n  publish_vector_field: true\n</code></pre>"},{"location":"tutorials/planner_and_controller/#obstacle-aware-planning","title":"Obstacle-aware planning","text":"<p>After the cost layers have been computed, the resulting vertex costs are transformed into edge costs inside the mesh map. In this step, the parameter of the mesh map <code>edge_cost_factor</code> determines how much the vertex costs are added (!) to the edge distance. We add the costs to the edge distances to preserve the admissible property of future heuristic search implementations: When using pre-computed distances or the air-line to the target as heuristics, the actual costs collected along the way will be always at least higher. </p> <p>Setting the <code>edge_cost_factor</code> parameter to zero will let the planners ignore all static obstacles. An example configuration that takes (static) obstacles into account while planning could be:</p> <pre><code>mesh_map:\n  # An edge cost equals the total costs that are collected along a \n  # triangle's edge by linearly interpolating the combined vertex costs\n  # This factor defines the factor that is used for the final edge weight\n  # -&gt; edge_weight = edge_length + edge_cost_factor * edge_cost\n  # This edge_weight is then passed to the global planner to search for \n  # the best path\n  # Note: Set this to 0.0 if you need the shortest path\n  edge_cost_factor: 5.0\n\n  # [...] Other parameters of mesh_map\n</code></pre>"},{"location":"tutorials/planner_and_controller/#controller","title":"Controller","text":"<p>Modern navigation on 3D surface meshes requires control strategies that can follow complex terrain while respecting the robot's kinematics. MeshNav provides multiple controllers tailored to this task\u2014from a simple vector-field\u2013based controller to a full Model Predictive Path Integral (MPPI) controller. This section introduces the available controllers, explains how they operate, and highlights when each should be used.</p>"},{"location":"tutorials/planner_and_controller/#vector-field-controller-default","title":"Vector Field Controller (Default)","text":"<p>The vector field controller is the default controller used in the tutorials. It takes the vector field that was attached to the mesh by the planner and controls the robot along the field until it arrives at the desired goal.</p> <p>Source Code: mesh_controller.</p> No Obstacle Avoidance <p>In the current implementation (!), the vector field does not react to the new dynamic obstacle layer. Therefore, it is not possible to respond to dynamic obstacles. Implementing this capability would be a substantial improvement. Don't forget to open a PR!</p>"},{"location":"tutorials/planner_and_controller/#mesh-mppi","title":"Mesh MPPI","text":"<p>MeshMPPI is an adaptation of the model predictive path integral (MPPI) control algorithm to surface meshes. The MPPI algorithm generates control signals by simulating the trajectories resulting from a set of random samples. This adaptation constrains the trajectory prediction to the surface defined by a triangular mesh. The implementation provided in this repository integrates the MeshMPPI algorithm into the ROS 2\u2013based MeshNav 3D navigation stack.</p> <p>It can be used when extra attention is needed to ensure that motion planning is both kinematically and terrain feasible. It currently implements two kinematic models that can be used with either differential-drive or bicycle-drive robots. Furthermore, it reacts to dynamic cost layers, enabling it to avoid dynamic or previously unmapped obstacles. Additionally, it provides a mechanism to easily extend the controller with custom kinematic models.</p> <p>Source Code: mesh_mppi, developed at Osnabr\u00fcck University (UOS).</p>"},{"location":"tutorials/tutorial_worlds/","title":"MeshNav Tutorial Worlds","text":"<p>For the tutorials we created a selection of virtual worlds, which we categorized in realistic and simplistic environments. Realistic worlds bring us closer to real-world conditions by modeling complex geometry, textures, and dynamics, which helps evaluate how algorithms perform in practice. Simplistic worlds, on the other hand, keep environments minimal so that examples can run even on low-end hardware and interesting situations can be studied in isolation without unnecessary complexity. This separation ensures both robustness testing under realistic conditions and efficient, focused experimentation when needed.</p>"},{"location":"tutorials/tutorial_worlds/#simple-worlds","title":"Simple Worlds","text":"<p>All files are located in the following packages:</p> <ul> <li>Maps &amp; MeshNav: <code>mesh_navigation_tutorials</code></li> <li>Worlds &amp; Simulation: <code>mesh_navigation_tutorials_sim</code></li> </ul>"},{"location":"tutorials/tutorial_worlds/#tray","title":"Tray","text":"<p>The most simplistic environment for very simple test cases.</p> RViz Gazebo <pre><code>ros2 launch mesh_navigation_tutorials mesh_navigation_tutorials_launch.py world_name:=tray\n</code></pre>"},{"location":"tutorials/tutorial_worlds/#floor-is-lava","title":"Floor Is Lava","text":"<p>A more sophisticated environments where the robot could fall down a bridge (into lava).</p> RViz Gazebo <pre><code>ros2 launch mesh_navigation_tutorials mesh_navigation_tutorials_launch.py world_name:=floor_is_lava\n</code></pre>"},{"location":"tutorials/tutorial_worlds/#parking-garage","title":"Parking Garage","text":"<p>A simple multi-story parking garage, demonstrating how mesh navigation enables efficient planning across different floors.</p> RViz Gazebo <pre><code>ros2 launch mesh_navigation_tutorials mesh_navigation_tutorials_launch.py world_name:=parking_garage\n</code></pre>"},{"location":"tutorials/tutorial_worlds/#download","title":"Download","text":"<p>All simple maps are automatically available after cloning the repository.</p>"},{"location":"tutorials/tutorial_worlds/#real-world-worlds","title":"Real World Worlds","text":"<p>Additionally, we provide larger maps that more closely resemble real-world scales. Because these maps also have a large file size, we use Git LFS to store them efficiently and to make downloading parts of the repository more manageable.</p>"},{"location":"tutorials/tutorial_worlds/#pluto-maps","title":"Pluto Maps","text":"<p>Originally used to benchmark the findings in the very first publications they are now revived for ROS 2. You can find the very first version of the code here: https://github.com/uos/pluto_robot.</p> <p>All files are located in the following packages:</p> <ul> <li>Maps &amp; MeshNav: <code>mesh_navigation_pluto</code></li> <li>Worlds &amp; Simulation: <code>mesh_navigation_pluto_sim</code></li> </ul>"},{"location":"tutorials/tutorial_worlds/#physics-campus-uos","title":"Physics Campus UOS","text":"<p>Physics building at Campus Westerberg, Osnabr\u00fcck University.</p> ID Vertices Triangles Dimensions: x[m], y[m], z[m] File Size <code>physics_campus_uos</code> 813 674 1 804 965 166.02 * 83.61 * 26.33 35M <p></p> <pre><code>ros2 launch mesh_navigation_pluto mesh_navigation_pluto_launch.py world_name:=physics_campus_uos\n</code></pre>"},{"location":"tutorials/tutorial_worlds/#botanical-garden-osnabruck","title":"Botanical Garden Osnabr\u00fcck","text":"ID Vertices Triangles Dimensions: x[m], y[m], z[m] File Size <code>botanical_garden_osnabrueck</code> 711 417 1 404 396 39.05 * 49.25 * 6.67 34M <pre><code>ros2 launch mesh_navigation_pluto mesh_navigation_pluto_launch.py world_name:=botanical_garden_osnabrueck\n</code></pre>"},{"location":"tutorials/tutorial_worlds/#stone-quarry-brockum","title":"Stone Quarry Brockum","text":"ID Vertices Triangles Dimensions: x[m], y[m], z[m] File Size <code>stone_quarry_brockum</code> 927 102 1 881 428 100.58 * 100.58 * 23.94 37M <pre><code>ros2 launch mesh_navigation_pluto mesh_navigation_pluto_launch.py world_name:=stone_quarry_brockum\n</code></pre>"},{"location":"tutorials/tutorial_worlds/#download_1","title":"Download","text":"<p>While being in the source directory of this repository, download all Pluto maps by entering</p> <pre><code>git lfs pull --include=\"mesh_navigation_pluto*\"\n</code></pre> <p>or specific ones by calling</p> <pre><code>git lfs pull --include=\"mesh_navigation_pluto*/**/physics_campus_uos*\"\n</code></pre>"},{"location":"tutorials/tutorial_worlds/#ceres-maps","title":"Ceres Maps","text":""},{"location":"tutorials/tutorial_worlds/#coppenrath-innovation-centre-cic-outdoors","title":"Coppenrath Innovation Centre (CIC) Outdoors","text":"<p>The CIC building contains tech companies and research facilities that focus on AI &amp; Robotics. Nature Robots is situated there as well as DFKI and UOS.</p> ID Vertices Triangles Dimensions: x[m], y[m], z[m] File Size <code>cic_outdoor</code> 1 067 684 1 967 419 284.06 * 276.64 * 26.3 57M RViz Gazebo <pre><code>ros2 launch mesh_navigation_ceres mesh_navigation_ceres_launch.py world_name:=cic_outdoor\n</code></pre>"},{"location":"tutorials/tutorial_worlds/#agro-technicum","title":"Agro-Technicum","text":"<p>Building of Osnabr\u00fcck University of Applied Sciences and Osnabotics.</p> ID Vertices Triangles Dimensions: x[m], y[m], z[m] File Size <code>agrotechnicum</code> 402 076 681 761 129.1 * 143.25 * 16.1 15M RViz Gazebo <pre><code>ros2 launch mesh_navigation_ceres mesh_navigation_ceres_launch.py world_name:=agrotechnicum\n</code></pre>"},{"location":"tutorials/tutorial_worlds/#fh-aachen-maskor","title":"FH Aachen (MASKOR)","text":"<p>The campus of FH Aachen digitalized from the MASKOR institute.</p> ID Vertices Triangles Dimensions: x[m], y[m], z[m] File Size <code>fh_aachen</code> 1 191 523 2 350 458 245.97 * 370.9 * 39.43 48M RViz Gazebo <pre><code>ros2 launch mesh_navigation_ceres mesh_navigation_ceres_launch.py world_name:=fh_aachen\n</code></pre>"},{"location":"tutorials/tutorial_worlds/#download_2","title":"Download","text":"<p>While being in the source directory of this repository, download all Pluto maps by entering</p> <pre><code>git lfs pull --include=\"mesh_navigation_ceres*\"\n</code></pre> <p>or specific ones by calling</p> <pre><code>git lfs pull --include=\"mesh_navigation_ceres*/**/cic_outdoor*\"\n</code></pre>"},{"location":"tutorials/gen_edit/align_mesh_to_ground/","title":"Align Mesh to Ground Plane","text":"<p>TODO: Write something</p> <p>Link: https://www.youtube.com/watch?v=FUYHixJfYQs</p>"},{"location":"tutorials/gen_edit/flatten_surface/","title":"Mesh Editing: Flatten a surface","text":"<p>TODO: Rewrite this</p> <p>Due to sensor inaccuracies flat floors sometimes are mapped roughly...</p> <p>straightened out the ground plane using Blender: </p> <ol> <li>enable ortographic view (numpad 5), </li> <li>look from the side (numpad 3),</li> <li>enable X-Ray (Alt-z),</li> <li>box select vertices,</li> <li>manually fix the selection, </li> <li>then scale z to 0 (s z 0)</li> </ol> <p>Link: https://www.youtube.com/watch?v=TmKt9RFphf0</p>"},{"location":"tutorials/gen_edit/mesh_mapping/","title":"Mesh Mapping","text":"<p>There are many different strategies to mesh your environment. Some of them consist of multiple steps, which gives a greater control about intermediate results. Others generate meshes directly, which makes it faster, but also harder to figure out potential flaws.</p> <p>Most of those strategies consist of a simultaneous localization and mapping (SLAM) software somewhere in the chain. For simplicity, we distinguish SLAM software by the data structure they operate on and generate as output.</p> <p>For example, point cloud (PCD) SLAM is a SLAM software that operates on point clouds and generates a large PCD of the environment. There are exceptions, for example voxel-based SLAM often operate on voxel-representations, also producing large voxel-maps as end result, but also producing a mesh as side-product, such as Warpsense. Then we still consider it as voxel-based SLAM and handle the mesh output as if it was before converted from a voxel-based representation to a mesh.  So Warpsense, for example, is a voxel-based SLAM and also a mesh conversion tool.</p> <p>Then, the following procedures are possible to obtain a mesh from your environment, using different SLAM approaches:</p> <p></p>"},{"location":"tutorials/gen_edit/mesh_mapping/#list-of-helpful-open-source-software","title":"List of Helpful Open-Source Software","text":""},{"location":"tutorials/gen_edit/mesh_mapping/#pcd-slam","title":"PCD SLAM","text":"<p>This list will grow. </p> Name Link MeshNav-proved? Point-LIO https://github.com/hku-mars/Point-LIO unknown MOLA https://github.com/MOLAorg/mola unknown Slam6D https://slam6d.sourceforge.io/ yes: Tested with high resulution Riegl scans GLIM https://github.com/koide3/glim yes: Guide Open3D https://www.open3d.org/ yes: scripts <p>The resulting PCD can be used to generate a mesh. See conversion tools.</p>"},{"location":"tutorials/gen_edit/mesh_mapping/#voxel-based-slam","title":"Voxel-based SLAM","text":"Name Link MeshNav-proved? voxblox https://github.com/ethz-asl/voxblox unknown nvblox https://github.com/nvidia-isaac/nvblox unknown Uni-Fusion https://github.com/Jarrome/Uni-Fusion unknown"},{"location":"tutorials/gen_edit/mesh_mapping/#mesh-slam","title":"Mesh SLAM","text":"Name Link MeshNav-proved? Kinect Fusion https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/ismar2011.pdf unknown PUMA https://github.com/PRBonn/puma unknown. unconnected mesh? SLAMesh https://github.com/lab-sun/SLAMesh unknown Warpsense https://github.com/juliangaal/warpsense unknown Kimera https://github.com/MIT-SPARK/Kimera-VIO unknown"},{"location":"tutorials/gen_edit/mesh_mapping/#other-slam","title":"Other SLAM","text":"Name Link MeshNav-proved? PIN SLAM https://github.com/PRBonn/PIN_SLAM unknown. In first test, mesh was corrupted so I couldn't traverse with the lvr2 half-edge mesh. Loopy-SLAM https://github.com/eriksandstroem/Loopy-SLAM unknown"},{"location":"tutorials/gen_edit/mesh_mapping/#conversion-tools","title":"Conversion Tools","text":"<p>It is also possible to convert certain data structures to others. Here a list:</p> Name Link Comments MeshNav-proved? lvr2 https://github.com/uos/lvr2 <code>lvr2_reconstruct</code> executable yes meshlab https://www.meshlab.net/ yes Open3D https://www.open3d.org/ Example Open3D scripts: Link yes"},{"location":"tutorials/gen_edit/mesh_mapping/#lvr2","title":"LVR2","text":"<p>The lvr2 project has a tool to reconstruct meshes from unordered point clouds:</p> <pre><code>./bin/lvr2_reconstruct input_pcd.ply\n</code></pre> <p>It uses the Marching Cubes algorithm to reconstruct a mesh from the <code>input_pcd.ply</code> and writes the resulting mesh to <code>triangle_mesh.ply</code>.</p> <p>The results look like this:</p> Point Cloud Triangle Mesh <p>The <code>lvr2_reconstruct</code> executable has many useful parameters that can be adjusted for different point cloud sizes, resultions, or environments. The parameters can be printed as follows:</p> <pre><code>./bin/lvr2_reconstruct --help\n</code></pre> <p>Some important parameters are:</p> Parameter Description <code>-v 0.2</code> Voxelsize for the Marching Cubes algorithm. Has to be set to the smallest possible triangle resolution you want to have. <code>--kn 5</code> Number of nearest neighbors used for PCD normal computation. This depends on the PCD density and other environmental factors. <code>--ki 10</code> Number of nearest neighbors used to interpolate the normals <code>--kd 10</code> Number of nearest neighbors of each voxel corner to compute the signed distance values. <p>There are more parameters that influence the way lvr2 is reconstructing surfaces from point clouds. My advise is to just test them and see what changes.</p>"},{"location":"tutorials/gen_edit/mesh_mapping/#meshlab","title":"Meshlab","text":"<p>MeshLab is an open-source software designed for processing and editing 3D triangular meshes, widely used for reconstructing surfaces from point clouds. It supports various algorithms to convert unstructured point clouds into coherent triangular meshes, such as Poisson surface reconstruction, and Marching Cubes.</p> <p>Further resources: - \"Meshing Point Clouds\": https://meshlabstuff.blogspot.com/2009/09/meshing-point-clouds.html</p>"},{"location":"tutorials/gen_edit/mesh_mapping/#open3d","title":"Open3D","text":"<p>Open3D is a versatile open-source library for 3D data processing that provides tools for surface reconstruction from point clouds using methods like Poisson reconstruction and alpha shapes. The following example showcases the usage of the python API to Poission reconstruction to extract surfaces:</p> <pre><code>import open3d as o3d\nimport sys\n\n# parameters for normal estimation for each point in PCD\nne_max_radius = 0.1 # choose this dependent on the scale and density of your PCD\nne_max_nn = 30 # choose this dependent on density of your PCD\n\n# parameters for poission reconstruction\npossion_depth = 11 # the higher the more details, the more RAM is used\ndensity_filter = 0.05 # filter surface patches with low 'evidence'\n\n# This script reconstructs surfaces from a point cloud using Poisson Surface reconstruction\n# using Open3D's API (version 0.18.0)\n# \n# Input: point cloud -&gt; Output: mesh\nif __name__ == '__main__':\n    file_in = sys.argv[1]\n    file_out = sys.argv[2]\n    pcd = o3d.io.read_point_cloud(file_in)\n\n    print(\"Estimating point normals...\")\n    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=ne_max_radius, max_nn=ne_max_nn))\n\n    print(\"Starting Poisson surface reconstruction...\")\n    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=depth)\n\n    print(\"Removing vertices with low Poission density\")\n    vertices_to_remove = densities &lt; np.quantile(densities, density_filter)\n    mesh.remove_vertices_by_index(np.where(vertices_to_remove)[0])\n\n    # Save the mesh\n    o3d.io.write_triangle_mesh(file_out, mesh)\n</code></pre> <p>Further examples can be inferred from the official Open3D documention page: https://www.open3d.org/docs/release/.</p>"},{"location":"tutorials/gen_edit/mesh_mapping/#optimization","title":"Optimization","text":"<p>After we generated a mesh using SLAM approaches, it often has a high resolution; normally, exactly as high as the internal voxel representation. However, we can reduce the number of faces at planar regions, while still describing the environment accurately.  This can be done using tools from various mesh editing software, such as Blender or meshlab.</p> <p>Or you can use the <code>lvr2_mesh_reduce</code> tool from the lvr2 project as follows:</p> <pre><code>./bin/lvr2_mesh_reduce input_mesh.ply -r 0.6\n</code></pre> <p>It reduces the number of faces by a ratio of 0.6 and writes the results to <code>reduced_mesh.ply</code>, which would look as follows:</p> Triangle Mesh Optimized Mesh <p>Warning: For malformed meshes, this tool will result in an PanicException. It's on our list of things that needed to be fixed. If you find a solution to that problem, please contact us.</p>"},{"location":"tutorials/gen_edit/repair_mesh/","title":"Explanation: Mesh Quality and MeshNav","text":""},{"location":"tutorials/gen_edit/repair_mesh/#repair-mesh-via-meshlab","title":"Repair Mesh via MeshLab","text":"<p>Open MeshLab and loading your mesh <pre><code>meshlab my_mesh.ply\n</code></pre></p>"},{"location":"tutorials/gen_edit/repair_mesh/#standard-cleanups","title":"Standard Cleanups","text":"<p>Sometimes the mesh contains duplicated vertices. This can indicate an unconnected region inside the mesh that should be connected. Only when it is properly connected can the MeshNav planner do its job correctly. To clean this up, MeshLab provides filters to remove duplicated vertices and faces:</p> <pre><code>Filters -&gt; Cleaning and Repairing -&gt; Remove Duplicated Vertices\n</code></pre> <pre><code>Filters -&gt; Cleaning and Repairing -&gt; Remove Duplicated Faces\n</code></pre> <p>After applying each filter, MeshLab gives a feedback how many elements were removed.</p>"},{"location":"tutorials/gen_edit/repair_mesh/#rare-repair-non-manifold-meshes","title":"(Rare) Repair Non-Manifold Meshes","text":"<p>In some occasions non-manifoldness of the mesh leads to unexpected behavior in any algorithm that needs to traverse over the surface. Meshlab has a function that removes faces that belong to a non manifold edge.</p> <pre><code>Filters -&gt; Cleaning and Repairing -&gt; Repair non Manifold Edges by Removing Faces\n</code></pre> <p>Do this until MeshLab's output prints that no face is removed anymore. After that select the filter</p> <pre><code>Filters -&gt; Cleaning and Repairing -&gt; Repair non Manifold Vertices by splitting\n</code></pre> <p>and enter <code>0.5</code> as vertex displacement ratio to avoid creating new duplicated vertices. Repeat that until MeshLab prints it has done no changes.</p>"},{"location":"tutorials/gen_edit/shrink_faces/","title":"Explanation: Vertex Density and MeshNav","text":"<p>This is the mesh of the <code>floor_is_lava</code> world used for simulation in the MeshNav tutorials, visualized with MeshLab.</p> <p>You may notice that the triangles are very large. As shown in MeshLab's statistics, the entire, rather complex environment is represented by just 86 faces (connecting 52 vertices).</p> <p>For many operations, this is desirable, as it greatly reduces the amount of data needed to represent a large environment:</p> <ul> <li> <p>Rendering: fewer triangles need to be projected onto the camera plane,</p> </li> <li> <p>Collisions: fewer potential contact faces need to be evaluated for physics simulation.</p> </li> </ul> <p>However, some algorithms require a certain triangle density to function properly. For example, the simulation of bending materials or (most importantly for you) MeshNav's current planner implementations. MeshNav's cost layer system computes costs per vertex. For example, it may compute the maximum height difference in the immediate vicinity of a vertex:</p> <p></p> <p>In this visualization, you can see that each edge is assigned a cost inferred from the two vertices it connects. In this case, the edge receives a \"bad\" value because both vertices are in a dangerous region. Other problems that arise when using such low-resolution meshes for planning include:</p> <ul> <li> <p>Graph search algorithms may be forced to choose dangerous paths.</p> </li> <li> <p>Cost inflation effects cannot be represented with sufficient resolution.</p> </li> </ul> <p>One solution is to prepare the map with faces that are small enough. Fortunately, once we have a mesh, this operation is relatively straightforward:</p> <p>Note</p> <p>This operation will increase the number of faces. It will likely also increase the computational requirements for some navigation operations performed on the mesh.</p>"},{"location":"tutorials/gen_edit/shrink_faces/#shrink-faces-via-meshlab","title":"Shrink Faces via MeshLab","text":"<p>Open the mesh in MeshLab. Then go to <code>Filters -&gt; Remeshing, Simplification, and Reconstruction</code> and select <code>Remeshing: Isotropic Explicit Remeshing</code>.</p> <p></p> <p>Set the \"Target Length\" and \"Max. Surface Distance\" absolute values.</p> 0.5 0.3 MeshLab  MeshLab  MeshNav  MeshNav  <p>In the bottom row, you can see MeshNav\u2019s inflation cost layer visualized in RViz. The higher the resolution of the triangles, the better we can represent the lethal area within the inscribed inflation radius of 0.4\u202fm.</p>"}]}